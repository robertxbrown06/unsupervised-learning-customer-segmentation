{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85e8009e",
   "metadata": {},
   "source": [
    "# **Customer Segmentation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef8e429",
   "metadata": {},
   "source": [
    "# **Milestone 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac938ce",
   "metadata": {},
   "source": [
    "**Note:** This is in continuation to the data preprocessing we did in Milestone 1. Results might differ if you have followed different steps in data preprocessing. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac2abaf",
   "metadata": {},
   "source": [
    "## Preparing Data for Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f7bad9",
   "metadata": {},
   "source": [
    "### Dropping columns that we will not use for segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec456758",
   "metadata": {},
   "source": [
    "The decision about which variables to use for clustering is a critically important decision that will have a big impact on the clustering solution. So we need to think carefully about the variables we will choose for clustering. Clearly, this is a step where a lot of contextual knowledge, creativity, and experimentation/iterations are needed.\n",
    "\n",
    "Moreover, we often use only a few of the data attributes for segmentation (the segmentation attributes) and use some of the remaining ones (the profiling attributes) only to profile the clusters. For example, in market research and market segmentation, we can use behavioral data for segmentation (to segment the customers based on their behavior like amount spent, units bought, etc.), and then use both demographic as well as behavioral data for profiling the segments found.\n",
    "\n",
    "Here, we will use the behavioral attributes for segmentation and drop the demographic attributes like Income, Age, and Family_Size. In addition to this, we need to drop some other columns which are mentioned below.\n",
    "\n",
    "* `Dt_Customer`: We have created the `Engaged_in_days` variable using the Dt_Customer variable. Hence, we can drop this variable as it will not help with segmentation.\n",
    "* `Complain`: About 95% of the customers didn't complain and have the same value for this column. This variable will not have a major impact on segmentation. Hence, we can drop this variable. \n",
    "* `day`:  We have created the `Engaged_in_days` variable using the 'day' variable. Hence, we can drop this variable as it will not help with segmentation.\n",
    "* `Status`: This column was created just to get the `Family_Size` variable that contains the information about the Status. Hence, we can drop this variable.\n",
    "* We also need to drop categorical variables like `Education` and `Marital_Status`, `Kids`, `Kidhome`, and `Teenhome` as distance-based algorithms cannot use the default distance like Euclidean to find the distance between categorical and numerical variables.\n",
    "* We can also drop categorical variables like `AcceptedCmp1`, `AcceptedCmp2`, `AcceptedCmp3`, `AcceptedCmp4`, `AcceptedCmp5`, and `Response` for which we have create the variable `TotalAcceptedCmp` which is the aggregate of all these variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48120eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries to help with reading and manipulating data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Libraries to help with data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# To scale the data using z-score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# To compute distances\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# To perform K-means clustering and compute Silhouette scores\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# To visualize the elbow curve and Silhouette scores\n",
    "# from yellowbrick.cluster import SilhouetteVisualizer\n",
    "\n",
    "# Importing PCA\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# To encode the variable\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Importing TSNE\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# To perform hierarchical clustering, compute cophenetic correlation, and create dendrograms\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, cophenet\n",
    "\n",
    "# To compute distances\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "# To import K-Medoids\n",
    "# from sklearn_extra.cluster import KMedoids\n",
    "\n",
    "# To import Gaussian Mixture\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "# To supress warnings\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d62e7ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0ce76d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping all the irrelevant columns and storing in data_model\n",
    "data_model = data.drop(\n",
    "    columns=[\n",
    "        \"Year_Birth\",\n",
    "        \"Dt_Customer\",\n",
    "        \"day\",\n",
    "        \"Complain\",\n",
    "        \"Response\",\n",
    "        \"AcceptedCmp1\",\n",
    "        \"AcceptedCmp2\",\n",
    "        \"AcceptedCmp3\",\n",
    "        \"AcceptedCmp4\",\n",
    "        \"AcceptedCmp5\",\n",
    "        \"Marital_Status\",\n",
    "        \"Status\",\n",
    "        \"Kids\",\n",
    "        'Education',\n",
    "        'Kidhome',\n",
    "        'Teenhome', 'Income','Age', 'Family_Size'\n",
    "    ],\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fad26b8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2227, 36)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the shape of new data \n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de55f99b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year_Birth</th>\n",
       "      <th>Education</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Income</th>\n",
       "      <th>Kidhome</th>\n",
       "      <th>Teenhome</th>\n",
       "      <th>Dt_Customer</th>\n",
       "      <th>Recency</th>\n",
       "      <th>MntWines</th>\n",
       "      <th>MntFruits</th>\n",
       "      <th>...</th>\n",
       "      <th>Age</th>\n",
       "      <th>Kids</th>\n",
       "      <th>Status</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Expenses</th>\n",
       "      <th>NumTotalPurchases</th>\n",
       "      <th>day</th>\n",
       "      <th>Engaged_in_days</th>\n",
       "      <th>TotalAcceptedCmp</th>\n",
       "      <th>AmountPerPurchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1957</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Single</td>\n",
       "      <td>58138.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-04-09</td>\n",
       "      <td>58</td>\n",
       "      <td>635</td>\n",
       "      <td>88</td>\n",
       "      <td>...</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1617</td>\n",
       "      <td>25</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>997</td>\n",
       "      <td>1</td>\n",
       "      <td>64.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1954</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Single</td>\n",
       "      <td>46344.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-08-03</td>\n",
       "      <td>38</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>62</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1965</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Relationship</td>\n",
       "      <td>71613.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-08-21</td>\n",
       "      <td>26</td>\n",
       "      <td>426</td>\n",
       "      <td>49</td>\n",
       "      <td>...</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>776</td>\n",
       "      <td>21</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>498</td>\n",
       "      <td>0</td>\n",
       "      <td>36.952381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1984</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Relationship</td>\n",
       "      <td>26646.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-10-02</td>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>53</td>\n",
       "      <td>8</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>6.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1981</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Relationship</td>\n",
       "      <td>58293.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-01-19</td>\n",
       "      <td>94</td>\n",
       "      <td>173</td>\n",
       "      <td>43</td>\n",
       "      <td>...</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>422</td>\n",
       "      <td>19</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>347</td>\n",
       "      <td>0</td>\n",
       "      <td>22.210526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year_Birth   Education Marital_Status   Income  Kidhome  Teenhome  \\\n",
       "0        1957  Graduation         Single  58138.0        0         0   \n",
       "1        1954  Graduation         Single  46344.0        1         1   \n",
       "2        1965  Graduation   Relationship  71613.0        0         0   \n",
       "3        1984  Graduation   Relationship  26646.0        1         0   \n",
       "4        1981         PhD   Relationship  58293.0        1         0   \n",
       "\n",
       "  Dt_Customer  Recency  MntWines  MntFruits  ...  Age  Kids  Status  \\\n",
       "0  2012-04-09       58       635         88  ...   59     0       1   \n",
       "1  2014-08-03       38        11          1  ...   62     2       1   \n",
       "2  2013-08-21       26       426         49  ...   51     0       2   \n",
       "3  2014-10-02       26        11          4  ...   32     1       2   \n",
       "4  2014-01-19       94       173         43  ...   35     1       2   \n",
       "\n",
       "   Family_Size  Expenses  NumTotalPurchases         day  Engaged_in_days  \\\n",
       "0            1      1617                 25  2015-01-01              997   \n",
       "1            3        27                  6  2015-01-01              151   \n",
       "2            2       776                 21  2015-01-01              498   \n",
       "3            3        53                  8  2015-01-01               91   \n",
       "4            3       422                 19  2015-01-01              347   \n",
       "\n",
       "   TotalAcceptedCmp  AmountPerPurchase  \n",
       "0                 1          64.680000  \n",
       "1                 0           4.500000  \n",
       "2                 0          36.952381  \n",
       "3                 0           6.625000  \n",
       "4                 0          22.210526  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check first five rows of new data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6baf94",
   "metadata": {},
   "source": [
    "**Let's plot the correlation plot after we've removed the irrelevant variables.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "611843da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year_Birth</th>\n",
       "      <th>Income</th>\n",
       "      <th>Kidhome</th>\n",
       "      <th>Teenhome</th>\n",
       "      <th>Recency</th>\n",
       "      <th>MntWines</th>\n",
       "      <th>MntFruits</th>\n",
       "      <th>MntMeatProducts</th>\n",
       "      <th>MntFishProducts</th>\n",
       "      <th>MntSweetProducts</th>\n",
       "      <th>...</th>\n",
       "      <th>Response</th>\n",
       "      <th>Age</th>\n",
       "      <th>Kids</th>\n",
       "      <th>Status</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Expenses</th>\n",
       "      <th>NumTotalPurchases</th>\n",
       "      <th>Engaged_in_days</th>\n",
       "      <th>TotalAcceptedCmp</th>\n",
       "      <th>AmountPerPurchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Year_Birth</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.211914</td>\n",
       "      <td>0.234287</td>\n",
       "      <td>-0.364301</td>\n",
       "      <td>-0.018149</td>\n",
       "      <td>-0.162688</td>\n",
       "      <td>-0.013358</td>\n",
       "      <td>-0.038422</td>\n",
       "      <td>-0.042066</td>\n",
       "      <td>-0.018937</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018924</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.096080</td>\n",
       "      <td>-0.001449</td>\n",
       "      <td>-0.080420</td>\n",
       "      <td>-0.116140</td>\n",
       "      <td>-0.185013</td>\n",
       "      <td>0.021778</td>\n",
       "      <td>0.007075</td>\n",
       "      <td>-0.046786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Income</th>\n",
       "      <td>-0.211914</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.528643</td>\n",
       "      <td>0.040388</td>\n",
       "      <td>0.005867</td>\n",
       "      <td>0.728320</td>\n",
       "      <td>0.535365</td>\n",
       "      <td>0.694043</td>\n",
       "      <td>0.550074</td>\n",
       "      <td>0.549860</td>\n",
       "      <td>...</td>\n",
       "      <td>0.174128</td>\n",
       "      <td>0.211914</td>\n",
       "      <td>-0.349396</td>\n",
       "      <td>-0.015144</td>\n",
       "      <td>-0.297656</td>\n",
       "      <td>0.820486</td>\n",
       "      <td>0.695995</td>\n",
       "      <td>-0.032276</td>\n",
       "      <td>0.364110</td>\n",
       "      <td>0.487375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kidhome</th>\n",
       "      <td>0.234287</td>\n",
       "      <td>-0.528643</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.036404</td>\n",
       "      <td>0.008666</td>\n",
       "      <td>-0.498523</td>\n",
       "      <td>-0.373718</td>\n",
       "      <td>-0.443464</td>\n",
       "      <td>-0.388808</td>\n",
       "      <td>-0.371877</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.080513</td>\n",
       "      <td>-0.234287</td>\n",
       "      <td>0.689902</td>\n",
       "      <td>0.023755</td>\n",
       "      <td>0.584494</td>\n",
       "      <td>-0.557371</td>\n",
       "      <td>-0.480776</td>\n",
       "      <td>-0.058220</td>\n",
       "      <td>-0.193973</td>\n",
       "      <td>-0.358130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Teenhome</th>\n",
       "      <td>-0.364301</td>\n",
       "      <td>0.040388</td>\n",
       "      <td>-0.036404</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.015935</td>\n",
       "      <td>0.003149</td>\n",
       "      <td>-0.177763</td>\n",
       "      <td>-0.267845</td>\n",
       "      <td>-0.205992</td>\n",
       "      <td>-0.164297</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.156150</td>\n",
       "      <td>0.364301</td>\n",
       "      <td>0.698308</td>\n",
       "      <td>0.030520</td>\n",
       "      <td>0.595033</td>\n",
       "      <td>-0.139743</td>\n",
       "      <td>0.132814</td>\n",
       "      <td>0.007748</td>\n",
       "      <td>-0.160545</td>\n",
       "      <td>-0.138725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recency</th>\n",
       "      <td>-0.018149</td>\n",
       "      <td>0.005867</td>\n",
       "      <td>0.008666</td>\n",
       "      <td>0.015935</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.016497</td>\n",
       "      <td>-0.003597</td>\n",
       "      <td>0.026406</td>\n",
       "      <td>0.001466</td>\n",
       "      <td>0.022854</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.199286</td>\n",
       "      <td>0.018149</td>\n",
       "      <td>0.017750</td>\n",
       "      <td>-0.003274</td>\n",
       "      <td>0.012988</td>\n",
       "      <td>0.021848</td>\n",
       "      <td>0.006927</td>\n",
       "      <td>0.032273</td>\n",
       "      <td>-0.090200</td>\n",
       "      <td>0.012920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MntWines</th>\n",
       "      <td>-0.162688</td>\n",
       "      <td>0.728320</td>\n",
       "      <td>-0.498523</td>\n",
       "      <td>0.003149</td>\n",
       "      <td>0.016497</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.387288</td>\n",
       "      <td>0.585911</td>\n",
       "      <td>0.397702</td>\n",
       "      <td>0.384568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.246304</td>\n",
       "      <td>0.162688</td>\n",
       "      <td>-0.354798</td>\n",
       "      <td>-0.007286</td>\n",
       "      <td>-0.297987</td>\n",
       "      <td>0.895839</td>\n",
       "      <td>0.720182</td>\n",
       "      <td>0.147679</td>\n",
       "      <td>0.489406</td>\n",
       "      <td>0.504485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MntFruits</th>\n",
       "      <td>-0.013358</td>\n",
       "      <td>0.535365</td>\n",
       "      <td>-0.373718</td>\n",
       "      <td>-0.177763</td>\n",
       "      <td>-0.003597</td>\n",
       "      <td>0.387288</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.562560</td>\n",
       "      <td>0.593784</td>\n",
       "      <td>0.566381</td>\n",
       "      <td>...</td>\n",
       "      <td>0.124984</td>\n",
       "      <td>0.013358</td>\n",
       "      <td>-0.396452</td>\n",
       "      <td>-0.026197</td>\n",
       "      <td>-0.342500</td>\n",
       "      <td>0.615259</td>\n",
       "      <td>0.459726</td>\n",
       "      <td>0.059198</td>\n",
       "      <td>0.171407</td>\n",
       "      <td>0.360031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MntMeatProducts</th>\n",
       "      <td>-0.038422</td>\n",
       "      <td>0.694043</td>\n",
       "      <td>-0.443464</td>\n",
       "      <td>-0.267845</td>\n",
       "      <td>0.026406</td>\n",
       "      <td>0.585911</td>\n",
       "      <td>0.562560</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.589627</td>\n",
       "      <td>0.544148</td>\n",
       "      <td>...</td>\n",
       "      <td>0.246902</td>\n",
       "      <td>0.038422</td>\n",
       "      <td>-0.511663</td>\n",
       "      <td>-0.028947</td>\n",
       "      <td>-0.439466</td>\n",
       "      <td>0.853360</td>\n",
       "      <td>0.548333</td>\n",
       "      <td>0.070015</td>\n",
       "      <td>0.342823</td>\n",
       "      <td>0.622484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MntFishProducts</th>\n",
       "      <td>-0.042066</td>\n",
       "      <td>0.550074</td>\n",
       "      <td>-0.388808</td>\n",
       "      <td>-0.205992</td>\n",
       "      <td>0.001466</td>\n",
       "      <td>0.397702</td>\n",
       "      <td>0.593784</td>\n",
       "      <td>0.589627</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.578814</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110385</td>\n",
       "      <td>0.042066</td>\n",
       "      <td>-0.427709</td>\n",
       "      <td>-0.018104</td>\n",
       "      <td>-0.364143</td>\n",
       "      <td>0.644700</td>\n",
       "      <td>0.473314</td>\n",
       "      <td>0.077067</td>\n",
       "      <td>0.179147</td>\n",
       "      <td>0.379950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MntSweetProducts</th>\n",
       "      <td>-0.018937</td>\n",
       "      <td>0.549860</td>\n",
       "      <td>-0.371877</td>\n",
       "      <td>-0.164297</td>\n",
       "      <td>0.022854</td>\n",
       "      <td>0.384568</td>\n",
       "      <td>0.566381</td>\n",
       "      <td>0.544148</td>\n",
       "      <td>0.578814</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.116329</td>\n",
       "      <td>0.018937</td>\n",
       "      <td>-0.385379</td>\n",
       "      <td>-0.020222</td>\n",
       "      <td>-0.330167</td>\n",
       "      <td>0.604963</td>\n",
       "      <td>0.477019</td>\n",
       "      <td>0.076605</td>\n",
       "      <td>0.198387</td>\n",
       "      <td>0.345816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MntGoldProds</th>\n",
       "      <td>-0.056948</td>\n",
       "      <td>0.411947</td>\n",
       "      <td>-0.351228</td>\n",
       "      <td>-0.022186</td>\n",
       "      <td>0.017284</td>\n",
       "      <td>0.384568</td>\n",
       "      <td>0.388861</td>\n",
       "      <td>0.365691</td>\n",
       "      <td>0.420859</td>\n",
       "      <td>0.367813</td>\n",
       "      <td>...</td>\n",
       "      <td>0.139468</td>\n",
       "      <td>0.056948</td>\n",
       "      <td>-0.267646</td>\n",
       "      <td>-0.030965</td>\n",
       "      <td>-0.238230</td>\n",
       "      <td>0.525005</td>\n",
       "      <td>0.499143</td>\n",
       "      <td>0.145053</td>\n",
       "      <td>0.201906</td>\n",
       "      <td>0.305317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumDealsPurchases</th>\n",
       "      <td>-0.074132</td>\n",
       "      <td>-0.134030</td>\n",
       "      <td>0.231626</td>\n",
       "      <td>0.395108</td>\n",
       "      <td>-0.003205</td>\n",
       "      <td>0.012932</td>\n",
       "      <td>-0.134672</td>\n",
       "      <td>-0.166664</td>\n",
       "      <td>-0.141893</td>\n",
       "      <td>-0.121728</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002965</td>\n",
       "      <td>0.074132</td>\n",
       "      <td>0.452117</td>\n",
       "      <td>0.022619</td>\n",
       "      <td>0.386761</td>\n",
       "      <td>-0.079190</td>\n",
       "      <td>0.348668</td>\n",
       "      <td>0.200251</td>\n",
       "      <td>-0.094161</td>\n",
       "      <td>-0.137797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumWebPurchases</th>\n",
       "      <td>-0.153556</td>\n",
       "      <td>0.492210</td>\n",
       "      <td>-0.365488</td>\n",
       "      <td>0.153598</td>\n",
       "      <td>-0.010778</td>\n",
       "      <td>0.540318</td>\n",
       "      <td>0.295004</td>\n",
       "      <td>0.314407</td>\n",
       "      <td>0.291225</td>\n",
       "      <td>0.346311</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146631</td>\n",
       "      <td>0.153556</td>\n",
       "      <td>-0.150525</td>\n",
       "      <td>-0.000660</td>\n",
       "      <td>-0.125140</td>\n",
       "      <td>0.523822</td>\n",
       "      <td>0.787529</td>\n",
       "      <td>0.171734</td>\n",
       "      <td>0.203589</td>\n",
       "      <td>0.213300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumCatalogPurchases</th>\n",
       "      <td>-0.140057</td>\n",
       "      <td>0.706912</td>\n",
       "      <td>-0.517627</td>\n",
       "      <td>-0.112854</td>\n",
       "      <td>0.030499</td>\n",
       "      <td>0.673141</td>\n",
       "      <td>0.514943</td>\n",
       "      <td>0.703492</td>\n",
       "      <td>0.564485</td>\n",
       "      <td>0.519439</td>\n",
       "      <td>...</td>\n",
       "      <td>0.235082</td>\n",
       "      <td>0.140057</td>\n",
       "      <td>-0.452512</td>\n",
       "      <td>-0.018315</td>\n",
       "      <td>-0.384817</td>\n",
       "      <td>0.795516</td>\n",
       "      <td>0.742060</td>\n",
       "      <td>0.087316</td>\n",
       "      <td>0.373420</td>\n",
       "      <td>0.412833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumStorePurchases</th>\n",
       "      <td>-0.139045</td>\n",
       "      <td>0.682373</td>\n",
       "      <td>-0.505579</td>\n",
       "      <td>0.046896</td>\n",
       "      <td>0.001055</td>\n",
       "      <td>0.641200</td>\n",
       "      <td>0.462069</td>\n",
       "      <td>0.509642</td>\n",
       "      <td>0.458695</td>\n",
       "      <td>0.447318</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036076</td>\n",
       "      <td>0.139045</td>\n",
       "      <td>-0.328162</td>\n",
       "      <td>0.005156</td>\n",
       "      <td>-0.269340</td>\n",
       "      <td>0.681398</td>\n",
       "      <td>0.831230</td>\n",
       "      <td>0.103223</td>\n",
       "      <td>0.170587</td>\n",
       "      <td>0.301919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumWebVisitsMonth</th>\n",
       "      <td>0.120560</td>\n",
       "      <td>-0.642226</td>\n",
       "      <td>0.451289</td>\n",
       "      <td>0.136906</td>\n",
       "      <td>-0.019731</td>\n",
       "      <td>-0.327064</td>\n",
       "      <td>-0.424519</td>\n",
       "      <td>-0.544101</td>\n",
       "      <td>-0.453369</td>\n",
       "      <td>-0.430668</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005778</td>\n",
       "      <td>-0.120560</td>\n",
       "      <td>0.422418</td>\n",
       "      <td>0.010635</td>\n",
       "      <td>0.355815</td>\n",
       "      <td>-0.502959</td>\n",
       "      <td>-0.312658</td>\n",
       "      <td>0.257462</td>\n",
       "      <td>-0.131090</td>\n",
       "      <td>-0.351280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AcceptedCmp3</th>\n",
       "      <td>0.061420</td>\n",
       "      <td>-0.011740</td>\n",
       "      <td>0.014532</td>\n",
       "      <td>-0.043623</td>\n",
       "      <td>-0.033173</td>\n",
       "      <td>0.061253</td>\n",
       "      <td>0.014284</td>\n",
       "      <td>0.020804</td>\n",
       "      <td>-0.000415</td>\n",
       "      <td>0.000696</td>\n",
       "      <td>...</td>\n",
       "      <td>0.253762</td>\n",
       "      <td>-0.061420</td>\n",
       "      <td>-0.021191</td>\n",
       "      <td>-0.018390</td>\n",
       "      <td>-0.027272</td>\n",
       "      <td>0.053529</td>\n",
       "      <td>0.020201</td>\n",
       "      <td>-0.006926</td>\n",
       "      <td>0.427773</td>\n",
       "      <td>0.022904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AcceptedCmp4</th>\n",
       "      <td>-0.064124</td>\n",
       "      <td>0.231171</td>\n",
       "      <td>-0.162213</td>\n",
       "      <td>0.038152</td>\n",
       "      <td>0.018823</td>\n",
       "      <td>0.373125</td>\n",
       "      <td>0.009689</td>\n",
       "      <td>0.108189</td>\n",
       "      <td>0.016087</td>\n",
       "      <td>0.027836</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176457</td>\n",
       "      <td>0.064124</td>\n",
       "      <td>-0.088552</td>\n",
       "      <td>-0.005999</td>\n",
       "      <td>-0.076579</td>\n",
       "      <td>0.254469</td>\n",
       "      <td>0.190781</td>\n",
       "      <td>0.015854</td>\n",
       "      <td>0.540250</td>\n",
       "      <td>0.214187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AcceptedCmp5</th>\n",
       "      <td>0.015657</td>\n",
       "      <td>0.415468</td>\n",
       "      <td>-0.205518</td>\n",
       "      <td>-0.191334</td>\n",
       "      <td>0.000846</td>\n",
       "      <td>0.471752</td>\n",
       "      <td>0.211516</td>\n",
       "      <td>0.385693</td>\n",
       "      <td>0.197592</td>\n",
       "      <td>0.258333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.327843</td>\n",
       "      <td>-0.015657</td>\n",
       "      <td>-0.285806</td>\n",
       "      <td>0.016403</td>\n",
       "      <td>-0.228290</td>\n",
       "      <td>0.470113</td>\n",
       "      <td>0.220140</td>\n",
       "      <td>-0.024239</td>\n",
       "      <td>0.676514</td>\n",
       "      <td>0.296100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AcceptedCmp1</th>\n",
       "      <td>-0.007947</td>\n",
       "      <td>0.343146</td>\n",
       "      <td>-0.172959</td>\n",
       "      <td>-0.141243</td>\n",
       "      <td>-0.019412</td>\n",
       "      <td>0.353996</td>\n",
       "      <td>0.194892</td>\n",
       "      <td>0.321520</td>\n",
       "      <td>0.260447</td>\n",
       "      <td>0.241385</td>\n",
       "      <td>...</td>\n",
       "      <td>0.293550</td>\n",
       "      <td>0.007947</td>\n",
       "      <td>-0.226200</td>\n",
       "      <td>0.008191</td>\n",
       "      <td>-0.183208</td>\n",
       "      <td>0.383363</td>\n",
       "      <td>0.221899</td>\n",
       "      <td>-0.036246</td>\n",
       "      <td>0.634606</td>\n",
       "      <td>0.226146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AcceptedCmp2</th>\n",
       "      <td>-0.014806</td>\n",
       "      <td>0.104488</td>\n",
       "      <td>-0.080106</td>\n",
       "      <td>-0.012566</td>\n",
       "      <td>-0.007987</td>\n",
       "      <td>0.211094</td>\n",
       "      <td>-0.010336</td>\n",
       "      <td>0.034194</td>\n",
       "      <td>0.005025</td>\n",
       "      <td>0.009735</td>\n",
       "      <td>...</td>\n",
       "      <td>0.162523</td>\n",
       "      <td>0.014806</td>\n",
       "      <td>-0.066480</td>\n",
       "      <td>0.002486</td>\n",
       "      <td>-0.053803</td>\n",
       "      <td>0.135533</td>\n",
       "      <td>0.079318</td>\n",
       "      <td>0.004261</td>\n",
       "      <td>0.404846</td>\n",
       "      <td>0.085205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Complain</th>\n",
       "      <td>-0.004379</td>\n",
       "      <td>-0.027734</td>\n",
       "      <td>0.036317</td>\n",
       "      <td>0.007366</td>\n",
       "      <td>0.005373</td>\n",
       "      <td>-0.036347</td>\n",
       "      <td>-0.003043</td>\n",
       "      <td>-0.020717</td>\n",
       "      <td>-0.019101</td>\n",
       "      <td>-0.020692</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.004379</td>\n",
       "      <td>0.031348</td>\n",
       "      <td>0.001032</td>\n",
       "      <td>0.026534</td>\n",
       "      <td>-0.033915</td>\n",
       "      <td>-0.016039</td>\n",
       "      <td>0.041542</td>\n",
       "      <td>-0.015889</td>\n",
       "      <td>-0.026721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Response</th>\n",
       "      <td>0.018924</td>\n",
       "      <td>0.174128</td>\n",
       "      <td>-0.080513</td>\n",
       "      <td>-0.156150</td>\n",
       "      <td>-0.199286</td>\n",
       "      <td>0.246304</td>\n",
       "      <td>0.124984</td>\n",
       "      <td>0.246902</td>\n",
       "      <td>0.110385</td>\n",
       "      <td>0.116329</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.018924</td>\n",
       "      <td>-0.170782</td>\n",
       "      <td>-0.150756</td>\n",
       "      <td>-0.221138</td>\n",
       "      <td>0.266550</td>\n",
       "      <td>0.155871</td>\n",
       "      <td>0.174320</td>\n",
       "      <td>0.724969</td>\n",
       "      <td>0.160745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.211914</td>\n",
       "      <td>-0.234287</td>\n",
       "      <td>0.364301</td>\n",
       "      <td>0.018149</td>\n",
       "      <td>0.162688</td>\n",
       "      <td>0.013358</td>\n",
       "      <td>0.038422</td>\n",
       "      <td>0.042066</td>\n",
       "      <td>0.018937</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018924</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.096080</td>\n",
       "      <td>0.001449</td>\n",
       "      <td>0.080420</td>\n",
       "      <td>0.116140</td>\n",
       "      <td>0.185013</td>\n",
       "      <td>-0.021778</td>\n",
       "      <td>-0.007075</td>\n",
       "      <td>0.046786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kids</th>\n",
       "      <td>-0.096080</td>\n",
       "      <td>-0.349396</td>\n",
       "      <td>0.689902</td>\n",
       "      <td>0.698308</td>\n",
       "      <td>0.017750</td>\n",
       "      <td>-0.354798</td>\n",
       "      <td>-0.396452</td>\n",
       "      <td>-0.511663</td>\n",
       "      <td>-0.427709</td>\n",
       "      <td>-0.385379</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.170782</td>\n",
       "      <td>0.096080</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.039123</td>\n",
       "      <td>0.849689</td>\n",
       "      <td>-0.500456</td>\n",
       "      <td>-0.248158</td>\n",
       "      <td>-0.036089</td>\n",
       "      <td>-0.255233</td>\n",
       "      <td>-0.357009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Status</th>\n",
       "      <td>-0.001449</td>\n",
       "      <td>-0.015144</td>\n",
       "      <td>0.023755</td>\n",
       "      <td>0.030520</td>\n",
       "      <td>-0.003274</td>\n",
       "      <td>-0.007286</td>\n",
       "      <td>-0.026197</td>\n",
       "      <td>-0.028947</td>\n",
       "      <td>-0.018104</td>\n",
       "      <td>-0.020222</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.150756</td>\n",
       "      <td>0.001449</td>\n",
       "      <td>0.039123</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.560123</td>\n",
       "      <td>-0.022105</td>\n",
       "      <td>0.000856</td>\n",
       "      <td>0.003608</td>\n",
       "      <td>-0.060256</td>\n",
       "      <td>-0.009320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Family_Size</th>\n",
       "      <td>-0.080420</td>\n",
       "      <td>-0.297656</td>\n",
       "      <td>0.584494</td>\n",
       "      <td>0.595033</td>\n",
       "      <td>0.012988</td>\n",
       "      <td>-0.297987</td>\n",
       "      <td>-0.342500</td>\n",
       "      <td>-0.439466</td>\n",
       "      <td>-0.364143</td>\n",
       "      <td>-0.330167</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.221138</td>\n",
       "      <td>0.080420</td>\n",
       "      <td>0.849689</td>\n",
       "      <td>0.560123</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.426565</td>\n",
       "      <td>-0.205282</td>\n",
       "      <td>-0.028015</td>\n",
       "      <td>-0.243396</td>\n",
       "      <td>-0.300894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Expenses</th>\n",
       "      <td>-0.116140</td>\n",
       "      <td>0.820486</td>\n",
       "      <td>-0.557371</td>\n",
       "      <td>-0.139743</td>\n",
       "      <td>0.021848</td>\n",
       "      <td>0.895839</td>\n",
       "      <td>0.615259</td>\n",
       "      <td>0.853360</td>\n",
       "      <td>0.644700</td>\n",
       "      <td>0.604963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.266550</td>\n",
       "      <td>0.116140</td>\n",
       "      <td>-0.500456</td>\n",
       "      <td>-0.022105</td>\n",
       "      <td>-0.426565</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.753296</td>\n",
       "      <td>0.137085</td>\n",
       "      <td>0.458174</td>\n",
       "      <td>0.618570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumTotalPurchases</th>\n",
       "      <td>-0.185013</td>\n",
       "      <td>0.695995</td>\n",
       "      <td>-0.480776</td>\n",
       "      <td>0.132814</td>\n",
       "      <td>0.006927</td>\n",
       "      <td>0.720182</td>\n",
       "      <td>0.459726</td>\n",
       "      <td>0.548333</td>\n",
       "      <td>0.473314</td>\n",
       "      <td>0.477019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.155871</td>\n",
       "      <td>0.185013</td>\n",
       "      <td>-0.248158</td>\n",
       "      <td>0.000856</td>\n",
       "      <td>-0.205282</td>\n",
       "      <td>0.753296</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.188415</td>\n",
       "      <td>0.260497</td>\n",
       "      <td>0.323528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Engaged_in_days</th>\n",
       "      <td>0.021778</td>\n",
       "      <td>-0.032276</td>\n",
       "      <td>-0.058220</td>\n",
       "      <td>0.007748</td>\n",
       "      <td>0.032273</td>\n",
       "      <td>0.147679</td>\n",
       "      <td>0.059198</td>\n",
       "      <td>0.070015</td>\n",
       "      <td>0.077067</td>\n",
       "      <td>0.076605</td>\n",
       "      <td>...</td>\n",
       "      <td>0.174320</td>\n",
       "      <td>-0.021778</td>\n",
       "      <td>-0.036089</td>\n",
       "      <td>0.003608</td>\n",
       "      <td>-0.028015</td>\n",
       "      <td>0.137085</td>\n",
       "      <td>0.188415</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.056038</td>\n",
       "      <td>0.076738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalAcceptedCmp</th>\n",
       "      <td>0.007075</td>\n",
       "      <td>0.364110</td>\n",
       "      <td>-0.193973</td>\n",
       "      <td>-0.160545</td>\n",
       "      <td>-0.090200</td>\n",
       "      <td>0.489406</td>\n",
       "      <td>0.171407</td>\n",
       "      <td>0.342823</td>\n",
       "      <td>0.179147</td>\n",
       "      <td>0.198387</td>\n",
       "      <td>...</td>\n",
       "      <td>0.724969</td>\n",
       "      <td>-0.007075</td>\n",
       "      <td>-0.255233</td>\n",
       "      <td>-0.060256</td>\n",
       "      <td>-0.243396</td>\n",
       "      <td>0.458174</td>\n",
       "      <td>0.260497</td>\n",
       "      <td>0.056038</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.294251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AmountPerPurchase</th>\n",
       "      <td>-0.046786</td>\n",
       "      <td>0.487375</td>\n",
       "      <td>-0.358130</td>\n",
       "      <td>-0.138725</td>\n",
       "      <td>0.012920</td>\n",
       "      <td>0.504485</td>\n",
       "      <td>0.360031</td>\n",
       "      <td>0.622484</td>\n",
       "      <td>0.379950</td>\n",
       "      <td>0.345816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160745</td>\n",
       "      <td>0.046786</td>\n",
       "      <td>-0.357009</td>\n",
       "      <td>-0.009320</td>\n",
       "      <td>-0.300894</td>\n",
       "      <td>0.618570</td>\n",
       "      <td>0.323528</td>\n",
       "      <td>0.076738</td>\n",
       "      <td>0.294251</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Year_Birth    Income   Kidhome  Teenhome   Recency  \\\n",
       "Year_Birth             1.000000 -0.211914  0.234287 -0.364301 -0.018149   \n",
       "Income                -0.211914  1.000000 -0.528643  0.040388  0.005867   \n",
       "Kidhome                0.234287 -0.528643  1.000000 -0.036404  0.008666   \n",
       "Teenhome              -0.364301  0.040388 -0.036404  1.000000  0.015935   \n",
       "Recency               -0.018149  0.005867  0.008666  0.015935  1.000000   \n",
       "MntWines              -0.162688  0.728320 -0.498523  0.003149  0.016497   \n",
       "MntFruits             -0.013358  0.535365 -0.373718 -0.177763 -0.003597   \n",
       "MntMeatProducts       -0.038422  0.694043 -0.443464 -0.267845  0.026406   \n",
       "MntFishProducts       -0.042066  0.550074 -0.388808 -0.205992  0.001466   \n",
       "MntSweetProducts      -0.018937  0.549860 -0.371877 -0.164297  0.022854   \n",
       "MntGoldProds          -0.056948  0.411947 -0.351228 -0.022186  0.017284   \n",
       "NumDealsPurchases     -0.074132 -0.134030  0.231626  0.395108 -0.003205   \n",
       "NumWebPurchases       -0.153556  0.492210 -0.365488  0.153598 -0.010778   \n",
       "NumCatalogPurchases   -0.140057  0.706912 -0.517627 -0.112854  0.030499   \n",
       "NumStorePurchases     -0.139045  0.682373 -0.505579  0.046896  0.001055   \n",
       "NumWebVisitsMonth      0.120560 -0.642226  0.451289  0.136906 -0.019731   \n",
       "AcceptedCmp3           0.061420 -0.011740  0.014532 -0.043623 -0.033173   \n",
       "AcceptedCmp4          -0.064124  0.231171 -0.162213  0.038152  0.018823   \n",
       "AcceptedCmp5           0.015657  0.415468 -0.205518 -0.191334  0.000846   \n",
       "AcceptedCmp1          -0.007947  0.343146 -0.172959 -0.141243 -0.019412   \n",
       "AcceptedCmp2          -0.014806  0.104488 -0.080106 -0.012566 -0.007987   \n",
       "Complain              -0.004379 -0.027734  0.036317  0.007366  0.005373   \n",
       "Response               0.018924  0.174128 -0.080513 -0.156150 -0.199286   \n",
       "Age                   -1.000000  0.211914 -0.234287  0.364301  0.018149   \n",
       "Kids                  -0.096080 -0.349396  0.689902  0.698308  0.017750   \n",
       "Status                -0.001449 -0.015144  0.023755  0.030520 -0.003274   \n",
       "Family_Size           -0.080420 -0.297656  0.584494  0.595033  0.012988   \n",
       "Expenses              -0.116140  0.820486 -0.557371 -0.139743  0.021848   \n",
       "NumTotalPurchases     -0.185013  0.695995 -0.480776  0.132814  0.006927   \n",
       "Engaged_in_days        0.021778 -0.032276 -0.058220  0.007748  0.032273   \n",
       "TotalAcceptedCmp       0.007075  0.364110 -0.193973 -0.160545 -0.090200   \n",
       "AmountPerPurchase     -0.046786  0.487375 -0.358130 -0.138725  0.012920   \n",
       "\n",
       "                     MntWines  MntFruits  MntMeatProducts  MntFishProducts  \\\n",
       "Year_Birth          -0.162688  -0.013358        -0.038422        -0.042066   \n",
       "Income               0.728320   0.535365         0.694043         0.550074   \n",
       "Kidhome             -0.498523  -0.373718        -0.443464        -0.388808   \n",
       "Teenhome             0.003149  -0.177763        -0.267845        -0.205992   \n",
       "Recency              0.016497  -0.003597         0.026406         0.001466   \n",
       "MntWines             1.000000   0.387288         0.585911         0.397702   \n",
       "MntFruits            0.387288   1.000000         0.562560         0.593784   \n",
       "MntMeatProducts      0.585911   0.562560         1.000000         0.589627   \n",
       "MntFishProducts      0.397702   0.593784         0.589627         1.000000   \n",
       "MntSweetProducts     0.384568   0.566381         0.544148         0.578814   \n",
       "MntGoldProds         0.384568   0.388861         0.365691         0.420859   \n",
       "NumDealsPurchases    0.012932  -0.134672        -0.166664        -0.141893   \n",
       "NumWebPurchases      0.540318   0.295004         0.314407         0.291225   \n",
       "NumCatalogPurchases  0.673141   0.514943         0.703492         0.564485   \n",
       "NumStorePurchases    0.641200   0.462069         0.509642         0.458695   \n",
       "NumWebVisitsMonth   -0.327064  -0.424519        -0.544101        -0.453369   \n",
       "AcceptedCmp3         0.061253   0.014284         0.020804        -0.000415   \n",
       "AcceptedCmp4         0.373125   0.009689         0.108189         0.016087   \n",
       "AcceptedCmp5         0.471752   0.211516         0.385693         0.197592   \n",
       "AcceptedCmp1         0.353996   0.194892         0.321520         0.260447   \n",
       "AcceptedCmp2         0.211094  -0.010336         0.034194         0.005025   \n",
       "Complain            -0.036347  -0.003043        -0.020717        -0.019101   \n",
       "Response             0.246304   0.124984         0.246902         0.110385   \n",
       "Age                  0.162688   0.013358         0.038422         0.042066   \n",
       "Kids                -0.354798  -0.396452        -0.511663        -0.427709   \n",
       "Status              -0.007286  -0.026197        -0.028947        -0.018104   \n",
       "Family_Size         -0.297987  -0.342500        -0.439466        -0.364143   \n",
       "Expenses             0.895839   0.615259         0.853360         0.644700   \n",
       "NumTotalPurchases    0.720182   0.459726         0.548333         0.473314   \n",
       "Engaged_in_days      0.147679   0.059198         0.070015         0.077067   \n",
       "TotalAcceptedCmp     0.489406   0.171407         0.342823         0.179147   \n",
       "AmountPerPurchase    0.504485   0.360031         0.622484         0.379950   \n",
       "\n",
       "                     MntSweetProducts  ...  Response       Age      Kids  \\\n",
       "Year_Birth                  -0.018937  ...  0.018924 -1.000000 -0.096080   \n",
       "Income                       0.549860  ...  0.174128  0.211914 -0.349396   \n",
       "Kidhome                     -0.371877  ... -0.080513 -0.234287  0.689902   \n",
       "Teenhome                    -0.164297  ... -0.156150  0.364301  0.698308   \n",
       "Recency                      0.022854  ... -0.199286  0.018149  0.017750   \n",
       "MntWines                     0.384568  ...  0.246304  0.162688 -0.354798   \n",
       "MntFruits                    0.566381  ...  0.124984  0.013358 -0.396452   \n",
       "MntMeatProducts              0.544148  ...  0.246902  0.038422 -0.511663   \n",
       "MntFishProducts              0.578814  ...  0.110385  0.042066 -0.427709   \n",
       "MntSweetProducts             1.000000  ...  0.116329  0.018937 -0.385379   \n",
       "MntGoldProds                 0.367813  ...  0.139468  0.056948 -0.267646   \n",
       "NumDealsPurchases           -0.121728  ...  0.002965  0.074132  0.452117   \n",
       "NumWebPurchases              0.346311  ...  0.146631  0.153556 -0.150525   \n",
       "NumCatalogPurchases          0.519439  ...  0.235082  0.140057 -0.452512   \n",
       "NumStorePurchases            0.447318  ...  0.036076  0.139045 -0.328162   \n",
       "NumWebVisitsMonth           -0.430668  ... -0.005778 -0.120560  0.422418   \n",
       "AcceptedCmp3                 0.000696  ...  0.253762 -0.061420 -0.021191   \n",
       "AcceptedCmp4                 0.027836  ...  0.176457  0.064124 -0.088552   \n",
       "AcceptedCmp5                 0.258333  ...  0.327843 -0.015657 -0.285806   \n",
       "AcceptedCmp1                 0.241385  ...  0.293550  0.007947 -0.226200   \n",
       "AcceptedCmp2                 0.009735  ...  0.162523  0.014806 -0.066480   \n",
       "Complain                    -0.020692  ...  0.000006  0.004379  0.031348   \n",
       "Response                     0.116329  ...  1.000000 -0.018924 -0.170782   \n",
       "Age                          0.018937  ... -0.018924  1.000000  0.096080   \n",
       "Kids                        -0.385379  ... -0.170782  0.096080  1.000000   \n",
       "Status                      -0.020222  ... -0.150756  0.001449  0.039123   \n",
       "Family_Size                 -0.330167  ... -0.221138  0.080420  0.849689   \n",
       "Expenses                     0.604963  ...  0.266550  0.116140 -0.500456   \n",
       "NumTotalPurchases            0.477019  ...  0.155871  0.185013 -0.248158   \n",
       "Engaged_in_days              0.076605  ...  0.174320 -0.021778 -0.036089   \n",
       "TotalAcceptedCmp             0.198387  ...  0.724969 -0.007075 -0.255233   \n",
       "AmountPerPurchase            0.345816  ...  0.160745  0.046786 -0.357009   \n",
       "\n",
       "                       Status  Family_Size  Expenses  NumTotalPurchases  \\\n",
       "Year_Birth          -0.001449    -0.080420 -0.116140          -0.185013   \n",
       "Income              -0.015144    -0.297656  0.820486           0.695995   \n",
       "Kidhome              0.023755     0.584494 -0.557371          -0.480776   \n",
       "Teenhome             0.030520     0.595033 -0.139743           0.132814   \n",
       "Recency             -0.003274     0.012988  0.021848           0.006927   \n",
       "MntWines            -0.007286    -0.297987  0.895839           0.720182   \n",
       "MntFruits           -0.026197    -0.342500  0.615259           0.459726   \n",
       "MntMeatProducts     -0.028947    -0.439466  0.853360           0.548333   \n",
       "MntFishProducts     -0.018104    -0.364143  0.644700           0.473314   \n",
       "MntSweetProducts    -0.020222    -0.330167  0.604963           0.477019   \n",
       "MntGoldProds        -0.030965    -0.238230  0.525005           0.499143   \n",
       "NumDealsPurchases    0.022619     0.386761 -0.079190           0.348668   \n",
       "NumWebPurchases     -0.000660    -0.125140  0.523822           0.787529   \n",
       "NumCatalogPurchases -0.018315    -0.384817  0.795516           0.742060   \n",
       "NumStorePurchases    0.005156    -0.269340  0.681398           0.831230   \n",
       "NumWebVisitsMonth    0.010635     0.355815 -0.502959          -0.312658   \n",
       "AcceptedCmp3        -0.018390    -0.027272  0.053529           0.020201   \n",
       "AcceptedCmp4        -0.005999    -0.076579  0.254469           0.190781   \n",
       "AcceptedCmp5         0.016403    -0.228290  0.470113           0.220140   \n",
       "AcceptedCmp1         0.008191    -0.183208  0.383363           0.221899   \n",
       "AcceptedCmp2         0.002486    -0.053803  0.135533           0.079318   \n",
       "Complain             0.001032     0.026534 -0.033915          -0.016039   \n",
       "Response            -0.150756    -0.221138  0.266550           0.155871   \n",
       "Age                  0.001449     0.080420  0.116140           0.185013   \n",
       "Kids                 0.039123     0.849689 -0.500456          -0.248158   \n",
       "Status               1.000000     0.560123 -0.022105           0.000856   \n",
       "Family_Size          0.560123     1.000000 -0.426565          -0.205282   \n",
       "Expenses            -0.022105    -0.426565  1.000000           0.753296   \n",
       "NumTotalPurchases    0.000856    -0.205282  0.753296           1.000000   \n",
       "Engaged_in_days      0.003608    -0.028015  0.137085           0.188415   \n",
       "TotalAcceptedCmp    -0.060256    -0.243396  0.458174           0.260497   \n",
       "AmountPerPurchase   -0.009320    -0.300894  0.618570           0.323528   \n",
       "\n",
       "                     Engaged_in_days  TotalAcceptedCmp  AmountPerPurchase  \n",
       "Year_Birth                  0.021778          0.007075          -0.046786  \n",
       "Income                     -0.032276          0.364110           0.487375  \n",
       "Kidhome                    -0.058220         -0.193973          -0.358130  \n",
       "Teenhome                    0.007748         -0.160545          -0.138725  \n",
       "Recency                     0.032273         -0.090200           0.012920  \n",
       "MntWines                    0.147679          0.489406           0.504485  \n",
       "MntFruits                   0.059198          0.171407           0.360031  \n",
       "MntMeatProducts             0.070015          0.342823           0.622484  \n",
       "MntFishProducts             0.077067          0.179147           0.379950  \n",
       "MntSweetProducts            0.076605          0.198387           0.345816  \n",
       "MntGoldProds                0.145053          0.201906           0.305317  \n",
       "NumDealsPurchases           0.200251         -0.094161          -0.137797  \n",
       "NumWebPurchases             0.171734          0.203589           0.213300  \n",
       "NumCatalogPurchases         0.087316          0.373420           0.412833  \n",
       "NumStorePurchases           0.103223          0.170587           0.301919  \n",
       "NumWebVisitsMonth           0.257462         -0.131090          -0.351280  \n",
       "AcceptedCmp3               -0.006926          0.427773           0.022904  \n",
       "AcceptedCmp4                0.015854          0.540250           0.214187  \n",
       "AcceptedCmp5               -0.024239          0.676514           0.296100  \n",
       "AcceptedCmp1               -0.036246          0.634606           0.226146  \n",
       "AcceptedCmp2                0.004261          0.404846           0.085205  \n",
       "Complain                    0.041542         -0.015889          -0.026721  \n",
       "Response                    0.174320          0.724969           0.160745  \n",
       "Age                        -0.021778         -0.007075           0.046786  \n",
       "Kids                       -0.036089         -0.255233          -0.357009  \n",
       "Status                      0.003608         -0.060256          -0.009320  \n",
       "Family_Size                -0.028015         -0.243396          -0.300894  \n",
       "Expenses                    0.137085          0.458174           0.618570  \n",
       "NumTotalPurchases           0.188415          0.260497           0.323528  \n",
       "Engaged_in_days             1.000000          0.056038           0.076738  \n",
       "TotalAcceptedCmp            0.056038          1.000000           0.294251  \n",
       "AmountPerPurchase           0.076738          0.294251           1.000000  \n",
       "\n",
       "[32 rows x 32 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot the correlation plot for new data\n",
    "data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a113f41",
   "metadata": {},
   "source": [
    "**Observations and Insights:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f86dd84",
   "metadata": {},
   "source": [
    "### Scaling the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754d65a4",
   "metadata": {},
   "source": [
    "**What is feature scaling?**\n",
    "\n",
    "Feature scaling is a class of statistical techniques that, as the name implies, scales the features of our data so that they all have a similar range. You'll understand better if we look at an example:\n",
    "\n",
    "If you have multiple independent variables like Age, Income, and Amount related variables, with their range as (18–100 Years), (25K–75K), and (100–200), respectively, feature scaling would help them all to be in the same range.\n",
    "\n",
    "**Why feature scaling is important in Unsupervised Learning?**\n",
    "\n",
    "Feature scaling is especially relevant in machine learning models that compute some sort of distance metric as we do in most clustering algorithms, for example, K-Means. \n",
    "\n",
    "So, scaling should be done to avoid the problem of one feature dominating over others because the unsupervised learning algorithm uses distance to find the similarity between data points."
   ]
  },
  {
   "attachments": {
    "SC.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "8f91b734",
   "metadata": {},
   "source": [
    "**Let's scale the data**\n",
    "\n",
    "**Standard Scaler**: StandardScaler standardizes a feature by subtracting the mean and then scaling to unit variance. Unit variance means dividing all the values by the standard deviation.\n",
    "\n",
    "![SC.png](attachment:SC.png)\n",
    "\n",
    "1. Data standardization is the process of rescaling the attributes so that they have a mean of 0 and a variance of 1.\n",
    "2. The ultimate goal to perform standardization is to bring down all the features to a common scale without distorting the differences in the range of the values.\n",
    "3. In sklearn.preprocessing.StandardScaler(), centering and scaling happen independently on each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1df3d120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2227 entries, 0 to 2226\n",
      "Data columns (total 36 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Year_Birth           2227 non-null   int64  \n",
      " 1   Education            2227 non-null   object \n",
      " 2   Marital_Status       2227 non-null   object \n",
      " 3   Income               2227 non-null   float64\n",
      " 4   Kidhome              2227 non-null   int64  \n",
      " 5   Teenhome             2227 non-null   int64  \n",
      " 6   Dt_Customer          2227 non-null   object \n",
      " 7   Recency              2227 non-null   int64  \n",
      " 8   MntWines             2227 non-null   int64  \n",
      " 9   MntFruits            2227 non-null   int64  \n",
      " 10  MntMeatProducts      2227 non-null   int64  \n",
      " 11  MntFishProducts      2227 non-null   int64  \n",
      " 12  MntSweetProducts     2227 non-null   int64  \n",
      " 13  MntGoldProds         2227 non-null   int64  \n",
      " 14  NumDealsPurchases    2227 non-null   int64  \n",
      " 15  NumWebPurchases      2227 non-null   int64  \n",
      " 16  NumCatalogPurchases  2227 non-null   int64  \n",
      " 17  NumStorePurchases    2227 non-null   int64  \n",
      " 18  NumWebVisitsMonth    2227 non-null   int64  \n",
      " 19  AcceptedCmp3         2227 non-null   int64  \n",
      " 20  AcceptedCmp4         2227 non-null   int64  \n",
      " 21  AcceptedCmp5         2227 non-null   int64  \n",
      " 22  AcceptedCmp1         2227 non-null   int64  \n",
      " 23  AcceptedCmp2         2227 non-null   int64  \n",
      " 24  Complain             2227 non-null   int64  \n",
      " 25  Response             2227 non-null   int64  \n",
      " 26  Age                  2227 non-null   int64  \n",
      " 27  Kids                 2227 non-null   int64  \n",
      " 28  Status               2227 non-null   int64  \n",
      " 29  Family_Size          2227 non-null   int64  \n",
      " 30  Expenses             2227 non-null   int64  \n",
      " 31  NumTotalPurchases    2227 non-null   int64  \n",
      " 32  day                  2227 non-null   object \n",
      " 33  Engaged_in_days      2227 non-null   int64  \n",
      " 34  TotalAcceptedCmp     2227 non-null   int64  \n",
      " 35  AmountPerPurchase    2227 non-null   float64\n",
      "dtypes: float64(2), int64(30), object(4)\n",
      "memory usage: 626.5+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1f5e791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Education', 'Marital_Status', 'Dt_Customer', 'day']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a list of categorical columns\n",
    "categorical_cols = data.select_dtypes(include=['object']).columns.tolist()\n",
    "categorical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2cc375f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Year_Birth',\n",
       " 'Income',\n",
       " 'Kidhome',\n",
       " 'Teenhome',\n",
       " 'Recency',\n",
       " 'MntWines',\n",
       " 'MntFruits',\n",
       " 'MntMeatProducts',\n",
       " 'MntFishProducts',\n",
       " 'MntSweetProducts',\n",
       " 'MntGoldProds',\n",
       " 'NumDealsPurchases',\n",
       " 'NumWebPurchases',\n",
       " 'NumCatalogPurchases',\n",
       " 'NumStorePurchases',\n",
       " 'NumWebVisitsMonth',\n",
       " 'AcceptedCmp3',\n",
       " 'AcceptedCmp4',\n",
       " 'AcceptedCmp5',\n",
       " 'AcceptedCmp1',\n",
       " 'AcceptedCmp2',\n",
       " 'Complain',\n",
       " 'Response',\n",
       " 'Age',\n",
       " 'Kids',\n",
       " 'Status',\n",
       " 'Family_Size',\n",
       " 'Expenses',\n",
       " 'NumTotalPurchases',\n",
       " 'Engaged_in_days',\n",
       " 'TotalAcceptedCmp',\n",
       " 'AmountPerPurchase']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a list of numerical columns\n",
    "numerical_cols = data.select_dtypes(exclude=['object']).columns.tolist()\n",
    "numerical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "480e4b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data[numerical_cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1132ce4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (2227, 32), indices imply (2227, 17)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_29604/3887625517.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdf_scaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnumerical_cols\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m                                     \u001b[1;31m# fit_transform the scaler function on new data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mdf_scaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m      \u001b[1;31m# Converting the embeddings to a dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mdf_scaled\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    670\u001b[0m                 )\n\u001b[0;32m    671\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 672\u001b[1;33m                 mgr = ndarray_to_mgr(\n\u001b[0m\u001b[0;32m    673\u001b[0m                     \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m                     \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mndarray_to_mgr\u001b[1;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[0;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m     \u001b[0m_check_values_indices_shape_match\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"array\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_check_values_indices_shape_match\u001b[1;34m(values, index, columns)\u001b[0m\n\u001b[0;32m    391\u001b[0m         \u001b[0mpassed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m         \u001b[0mimplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 393\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Shape of passed values is {passed}, indices imply {implied}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Shape of passed values is (2227, 32), indices imply (2227, 17)"
     ]
    }
   ],
   "source": [
    "# Applying standard scaler on new data numerical columns\n",
    "scaler = StandardScaler()                                                   # Initialize the Standard Scaler\n",
    "\n",
    "df_scaled = scaler.fit_transform(data[numerical_cols])                                     # fit_transform the scaler function on new data\n",
    "\n",
    "df_scaled = pd.DataFrame(df_scaled, columns=data_model.columns)      # Converting the embeddings to a dataframe\n",
    "\n",
    "df_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d39752f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Graduation'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_29604/2344058735.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m                                                   \u001b[1;31m# Initialize the Standard Scaler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdf_scaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m                                     \u001b[1;31m# fit_transform the scaler function on new data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mdf_scaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m      \u001b[1;31m# Converting the embeddings to a dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    865\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    866\u001b[0m             \u001b[1;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 867\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    868\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    869\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    807\u001b[0m         \u001b[1;31m# Reset internal state before fitting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    808\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 809\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    811\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    842\u001b[0m         \"\"\"\n\u001b[0;32m    843\u001b[0m         \u001b[0mfirst_call\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"n_samples_seen_\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 844\u001b[1;33m         X = self._validate_data(\n\u001b[0m\u001b[0;32m    845\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    846\u001b[0m             \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    575\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Validation should be done on X, y or both.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    576\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 577\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"X\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    578\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    854\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    855\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 856\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    857\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m                 raise ValueError(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order, like)\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_asarray_with_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlike\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlike\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1991\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1992\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mNpDtype\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1993\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1994\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1995\u001b[0m     def __array_wrap__(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order, like)\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_asarray_with_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlike\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlike\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Graduation'"
     ]
    }
   ],
   "source": [
    "# Applying standard scaler on new data\n",
    "scaler = StandardScaler()                                                   # Initialize the Standard Scaler\n",
    "\n",
    "df_scaled = scaler.fit_transform(data)                                     # fit_transform the scaler function on new data\n",
    "\n",
    "df_scaled = pd.DataFrame(df_scaled, columns=data_model.columns)      # Converting the embeddings to a dataframe\n",
    "\n",
    "df_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1a656f",
   "metadata": {},
   "source": [
    "## **Applying T-SNE and PCA to the data to visualize the data distributed in 2 dimensions**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0324acb",
   "metadata": {},
   "source": [
    "### **Applying T-SNE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c3539d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting T-SNE with number of components equal to 2 to visualize how data is distributed\n",
    "\n",
    "tsne = _____________        # Initializing T-SNE with number of component equal to 2, random_state=1, and perplexity=35\n",
    "\n",
    "data_air_pol_tsne = ___________                            # fit_transform T-SNE on new data\n",
    "\n",
    "data_air_pol_tsne = pd.DataFrame(data_air_pol_tsne, columns=[0, 1])           # Converting the embeddings to a dataframe\n",
    "\n",
    "plt.figure(figsize=(7, 7))                                                    # Scatter plot for two components\n",
    "\n",
    "sns.scatterplot(x=0, y=1, data=data_air_pol_tsne)                             # Plotting T-SNE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5f30dc",
   "metadata": {},
   "source": [
    "**Observation and Insights:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f715ff",
   "metadata": {},
   "source": [
    "### **Applying PCA**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f028e30",
   "metadata": {},
   "source": [
    "**Think about it:**\n",
    "- Should we apply clustering algorithms on the current data or should we apply PCA on the data before applying clustering algorithms? How would this help?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132914a3",
   "metadata": {},
   "source": [
    "When the variables used in clustering are highly correlated, it causes multicollinearity, which affects the clustering method and results in poor cluster profiling (or biased toward a few variables). PCA can be used to reduce the multicollinearity between the variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "482ba0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the number of principal components to generate\n",
    "n = data_model.shape[1]                                        # Storing the number of variables in the data\n",
    "\n",
    "pca = _________________                                        # Initialize PCA with n_components = n and random_state=1\n",
    "\n",
    "data_pca = pd.DataFrame(pca.____________)                      # fit_transform PCA on the scaled data\n",
    "\n",
    "# The percentage of variance explained by each principal component is stored\n",
    "exp_var = pca.explained_variance_ratio_                     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0305f9e8",
   "metadata": {},
   "source": [
    "**Let's plot the first two components and see how the data points are distributed.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f408dbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot for two components using the dataframe data_pca\n",
    "____________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5856be29",
   "metadata": {},
   "source": [
    "**Let's apply clustering algorithms on the data generated after applying PCA**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55dd08b",
   "metadata": {},
   "source": [
    "## **K-Means** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f055a8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "distortions = []                                                  # Create an empty list\n",
    "\n",
    "K = range(2, 10)                                                  # Setting the K range from 2 to 10\n",
    "\n",
    "for k in K:\n",
    "    kmeanModel = KMeans(n_clusters=k,random_state=4)              # Initialize K-Means\n",
    "    kmeanModel.fit(data_pca)                                      # Fit K-Means on the data\n",
    "    distortions.append(kmeanModel.inertia_)                       # Append distortion values to the empty list created above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b2a849a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the elbow plot\n",
    "plt.figure(figsize=(16, 8))                                            # Setting the plot size\n",
    "\n",
    "plt.plot(K, distortions, \"bx-\")                                        # Plotting the K on X-axis and distortions on y-axis\n",
    "\n",
    "plt.xlabel(\"k\")                                                        # Title of x-axis\n",
    "\n",
    "plt.ylabel(\"Distortion\")                                               # Title of y-axis\n",
    "\n",
    "plt.title(\"The Elbow Method showing the optimal k\")                    # Title of the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3857aa08",
   "metadata": {},
   "source": [
    "**In the above plot, the elbow is seen for K=3 and K=5 as there is some drop in distortion at K=3 and K=5.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfa1df7",
   "metadata": {},
   "source": [
    "**Think About It:**\n",
    "\n",
    "- How do we determine the optimal K value when the elbows are observed at 2 or more K values from the elbow curve?\n",
    "- Which metric can be used to determine the final K value?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcc3d32",
   "metadata": {},
   "source": [
    "**We can use the silhouette score as a metric for different K values to make a better decision about picking the number of clusters(K).**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e55428",
   "metadata": {},
   "source": [
    "### **What is the silhouette score?**\n",
    "\n",
    "Silhouette score is one of the methods for evaluating the quality of clusters created using clustering algorithms such as K-Means. The silhouette score is a measure of how similar an object is to its cluster (cohesion) compared to other clusters (separation). Silhouette score has a range of [-1, 1].\n",
    "\n",
    "* Silhouette coefficients near +1 indicate that the clusters are dense and well separated, which is good.\n",
    "* Silhouette score near -1 indicates that those samples might have been assigned to the wrong cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0e5c3e",
   "metadata": {},
   "source": [
    "**Finding silhouette score for each value of K**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3f65f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sil_score = []                                                             # Creating empty list\n",
    "cluster_list = range(3, 7)                                                 # Creating a range from 3 to 7\n",
    "for n_clusters in cluster_list:\n",
    "    \n",
    "    # Initialize K-Means with number of clusters equal to n_clusters and random_state=1\n",
    "    clusterer = _______________\n",
    "    \n",
    "    # Fit and predict on the pca data\n",
    "    preds = clusterer._________ \n",
    "    \n",
    "    # Calculate silhouette score - Hint: Use silhouette_score() function\n",
    "    score = ___________  \n",
    "    \n",
    "    # Append silhouette score to empty list created above\n",
    "    __________         \n",
    "    \n",
    "    # Print the silhouette score\n",
    "    print( \"For n_clusters = {}, the silhouette score is {})\".format(n_clusters, score))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccc59a8",
   "metadata": {},
   "source": [
    "**From the above silhouette scores, 3 appears to be a good value of K. So, let's build K-Means using K=3.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9f50a7",
   "metadata": {},
   "source": [
    "### **Applying K-Means on data_pca**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed152db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = _____________                                # Initialize the K-Means algorithm with 3 clusters and random_state=1\n",
    "\n",
    "kmeans.__________                                     # Fitting on the data_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ba4823f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pca[\"K_means_segments_3\"] = kmeans.labels_                    # Adding K-Means cluster labels to the data_pca data\n",
    "\n",
    "data[\"K_means_segments_3\"] = kmeans.labels_                        # Adding K-Means cluster labels to the whole data\n",
    "\n",
    "data_model[\"K_means_segments_3\"] = kmeans.labels_                  # Adding K-Means cluster labels to data_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b79c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the distribution\n",
    "data_model[\"K_means_segments_3\"]._________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39115d43",
   "metadata": {},
   "source": [
    "**Let's visualize the clusters using PCA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3847ec74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to visualize PCA data with clusters formed\n",
    "def PCA_PLOT(X, Y, PCA, cluster):\n",
    "    sns.scatterplot(x=X, y=1, data=PCA, hue=cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9f9cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA_PLOT(0, 1, data_pca, \"K_means_segments_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7058a4a7",
   "metadata": {},
   "source": [
    "**Observations and Insights:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddfd387",
   "metadata": {},
   "source": [
    "### **Cluster Profiling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "eaaa0291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking the cluster-wise mean of all the variables. Hint: First groupby 'data' by 'K_means_segments_3' and then find mean\n",
    "cluster_profile_KMeans_3 = _____________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518ed9ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Highlighting the maximum average value among all the clusters for each of the variables\n",
    "cluster_profile_KMeans_3.style.highlight_max(color=\"lightgreen\", axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f3b350",
   "metadata": {},
   "source": [
    "**Observations and Insights:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81af8109",
   "metadata": {},
   "source": [
    "**Let us create a boxplot for each of the variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "689b06e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to use in boxplot\n",
    "col_for_box = ['Income','Kidhome','Teenhome','Recency','MntWines','MntFruits','MntMeatProducts','MntFishProducts','MntSweetProducts','MntGoldProds','NumDealsPurchases','NumWebPurchases','NumCatalogPurchases','NumStorePurchases','NumWebVisitsMonth','Complain','Age','Family_Size','Expenses','NumTotalPurchases','Engaged_in_days','TotalAcceptedCmp','AmountPerPurchase']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b312bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating boxplot for each of the variables\n",
    "all_col = col_for_box\n",
    "\n",
    "plt.figure(figsize = (30, 50))\n",
    "\n",
    "for i, variable in enumerate(all_col):\n",
    "    plt.subplot(6, 4, i + 1)\n",
    "    \n",
    "    sns.__________(y=data[variable], x=data['K_means_segments_3'],showmeans=True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.title(variable)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380bb5d4",
   "metadata": {},
   "source": [
    "### **Characteristics of each cluster:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd1a949",
   "metadata": {},
   "source": [
    "**Cluster 0:__________**\n",
    "\n",
    "**Summary for cluster 0:_______________** \n",
    "\n",
    "**Cluster 1:_______________**\n",
    "\n",
    "**Summary for cluster 1:_______________**\n",
    "\n",
    "\n",
    "\n",
    "**Cluster 2:_______________** \n",
    "\n",
    "**Summary for cluster 2:_______________**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f8b3d0",
   "metadata": {},
   "source": [
    "**Think About It:**\n",
    "- Are the K-Means profiles with K=3 providing any deep insights into customer purchasing behavior or which channels they are using?\n",
    "- What is the next step to get more meaningful insights? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a8e859",
   "metadata": {},
   "source": [
    "We can see from the above profiles that K=3 segments the customers into High, Medium and Low-income customers, and we are not getting deep insights into different types of customers. So, let's try to build K=5 (which has another elbow in the Elbow curve) and see if we can get better cluster profiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ed9bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping labels we got from K=3 since we will be using PCA data for prediction\n",
    "# Drop K_means_segments_3. Hint: Use axis=1 and inplace=True\n",
    "data_pca._______\n",
    "data._______"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79fb95f",
   "metadata": {},
   "source": [
    "**Let's build K-Means using K=5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3548bf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the K-Means algorithm using number of cluster as 5 and random_state=0 on data_pca\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2e0d6ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add K-Means cluster labels to data_pca\n",
    "\n",
    "# Add K-Means cluster labels to whole data\n",
    "\n",
    "# Add K-Means cluster labels to data_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498c9bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the distribution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8177be",
   "metadata": {},
   "source": [
    "**Let's visualize the clusters using PCA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd8acff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hint: Use PCA_PLOT function created above\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65ce959",
   "metadata": {},
   "source": [
    "### **Cluster Profiling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f7793cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the cluster-wise mean of all the variables. Hint: First groupby 'data' by cluster labels column and then find mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c714ce5c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Highlight the maximum average value among all the clusters for each of the variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2964b3",
   "metadata": {},
   "source": [
    "**Let's plot the boxplot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c233433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create boxplot for each of the variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d533fc",
   "metadata": {},
   "source": [
    "### **Characteristics of each cluster**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc42d2d3",
   "metadata": {},
   "source": [
    "**Cluster 0:__________**\n",
    "\n",
    "**Summary for cluster 0:_______________** \n",
    "\n",
    "**Cluster 1:_______________**\n",
    "\n",
    "**Summary for cluster 1:_______________**\n",
    "\n",
    "\n",
    "**Cluster 2:_______________** \n",
    "\n",
    "**Summary for cluster 2:_______________**\n",
    "\n",
    "**Cluster 3:_______________** \n",
    "\n",
    "**Summary for cluster 3:_______________**\n",
    "\n",
    "**Cluster 4:_______________** \n",
    "\n",
    "**Summary for cluster 4:_______________**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c296e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping labels we got from K-Means since we will be using PCA data for prediction\n",
    "# Hint: Use axis=1 and inplace=True\n",
    "data_pca._____________\n",
    "data.____________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d943ef79",
   "metadata": {},
   "source": [
    "From the above profiles, K=5 provides more interesting insights about customer's purchasing behavior and preferred channels for purchasing products. We can also see that the High, Medium and Low income groups have different age groups and preferences, which was not evident in K=3. So, **we can choose K=5.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e598e6d5",
   "metadata": {},
   "source": [
    "## **K-Medoids**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1369fd9",
   "metadata": {},
   "source": [
    "**Let's find the silhouette score for K=5 in K-Medoids**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5860e7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmedo = ____________           # Initializing K-Medoids with number of clusters as 5 and random_state=1\n",
    "\n",
    "preds = ___________            # Fit and predict K-Medoids using data_pca\n",
    "\n",
    "score = ____________           # Calculate the silhouette score\n",
    "\n",
    "print(score)                   # Print the score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4c3698",
   "metadata": {},
   "source": [
    "**Observations and Insights:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "50a3695d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting on data_pca and ddding K-Medoids cluster labels to the whole data\n",
    "\n",
    "# Predicting on data_pca and ddding K-Medoids cluster labels to data_model\n",
    "\n",
    "# Predicting on data_pca and ddding K-Medoids cluster labels to data_pca\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edebcc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the distribution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93f8763",
   "metadata": {},
   "source": [
    "**Let's visualize the clusters using PCA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f87f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hint: Use PCA_PLOT function created above\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5c9271",
   "metadata": {},
   "source": [
    "### **Cluster Profiling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "466c8f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the cluster-wise mean of all the variables. Hint: First group 'data' by cluster labels column and then find mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a594f4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Highlight the maximum average value among all the clusters for each of the variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ea3508",
   "metadata": {},
   "source": [
    "**Let's plot the boxplot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23eac924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create boxplot for each of the variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7b8741",
   "metadata": {},
   "source": [
    "### **Characteristics of each cluster**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d17f83a",
   "metadata": {},
   "source": [
    "**Cluster 0:__________**\n",
    "\n",
    "**Summary for cluster 0:_______________** \n",
    "\n",
    "**Cluster 1:_______________**\n",
    "\n",
    "**Summary for cluster 1:_______________**\n",
    "\n",
    "\n",
    "**Cluster 2:_______________** \n",
    "\n",
    "**Summary for cluster 2:_______________**\n",
    "\n",
    "**Cluster 3:_______________** \n",
    "\n",
    "**Summary for cluster 3:_______________**\n",
    "\n",
    "**Cluster 4:_______________** \n",
    "\n",
    "**Summary for cluster 4:_______________**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "62ea4ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping labels we got from K-Medoids since we will be using PCA data for prediction\n",
    "# Hint: Use axis=1 and inplace=True\n",
    "data_pca._____________\n",
    "data.____________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424dd661",
   "metadata": {},
   "source": [
    "## **Hierarchical Clustering**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020ceab2",
   "metadata": {},
   "source": [
    "Let's find the Cophenetic correlation for different distances with different linkage methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb02ef61",
   "metadata": {},
   "source": [
    "### **What is a Cophenetic correlation?**\n",
    "\n",
    "The cophenetic correlation coefficient is a correlation coefficient between the cophenetic distances(Dendrogramic distance) obtained from the tree, and the original distances used to construct the tree. It is a measure of how faithfully a dendrogram preserves the pairwise distances between the original unmodeled data points. \n",
    "\n",
    "The cophenetic distance between two observations is represented in a dendrogram by the height of the link at which those two observations are first joined. That height is the distance between the two subclusters that are merged by that link.\n",
    "\n",
    "Cophenetic correlation is the way to compare two or more dendrograms. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c25567",
   "metadata": {},
   "source": [
    "**Let's calculate Cophenetic correlation for each of the distance metrics with each of the linkage methods**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c1c251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of distance metrics\n",
    "distance_metrics = [\"euclidean\", \"chebyshev\", \"mahalanobis\", \"cityblock\"]\n",
    "\n",
    "# list of linkage methods\n",
    "linkage_methods = [\"single\", \"complete\", \"average\"]\n",
    "\n",
    "high_cophenet_corr = 0                                                 # Creating a variable by assigning 0 to it\n",
    "high_dm_lm = [0, 0]                                                    # Creating a list by assigning 0's to it\n",
    "\n",
    "for dm in distance_metrics:\n",
    "    for lm in linkage_methods:\n",
    "        Z = linkage(data_pca, metric=dm, method=lm)                    # Applying different linkages with different distance on data_pca\n",
    "        c, coph_dists = cophenet(Z, pdist(data_pca))                   # Calculating cophenetic correlation\n",
    "        print(\n",
    "            \"Cophenetic correlation for {} distance and {} linkage is {}.\".format(\n",
    "                dm.capitalize(), lm, c\n",
    "            )\n",
    "        )\n",
    "        if high_cophenet_corr < c:                                     # Checking if cophenetic correlation is higher than previous score\n",
    "            high_cophenet_corr = c                                     # Appending to high_cophenet_corr list if it is higher\n",
    "            high_dm_lm[0] = dm                                         # Appending its corresponding distance\n",
    "            high_dm_lm[1] = lm                                         # Appending its corresponding method or linkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f0c62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the combination of distance metric and linkage method with the highest cophenetic correlation\n",
    "print(\n",
    "    \"Highest cophenetic correlation is {}, which is obtained with {} distance and {} linkage.\".format(\n",
    "        high_cophenet_corr, high_dm_lm[0].capitalize(), high_dm_lm[1]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8c31bb",
   "metadata": {},
   "source": [
    "**Let's have a look at the dendrograms for different linkages with `Cityblock distance`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a1aa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of linkage methods\n",
    "linkage_methods = [\"single\", \"complete\", \"average\"]\n",
    "\n",
    "# Lists to save results of cophenetic correlation calculation\n",
    "compare_cols = [\"Linkage\", \"Cophenetic Coefficient\"]\n",
    "\n",
    "# To create a subplot image\n",
    "fig, axs = plt.subplots(len(linkage_methods), 1, figsize=(15, 30))            # Setting the plot size\n",
    "\n",
    "# We will enumerate through the list of linkage methods above\n",
    "# For each linkage method, we will plot the dendrogram and calculate the cophenetic correlation\n",
    "for i, method in enumerate(linkage_methods):\n",
    "    Z = linkage(data_pca, metric=\"Cityblock\", method=method)                  # Measures the distances between two clusters\n",
    "\n",
    "    dendrogram(Z, ax=axs[i])\n",
    "    axs[i].set_title(f\"Dendrogram ({method.capitalize()} Linkage)\")           # Title of dendrogram\n",
    "\n",
    "    coph_corr, coph_dist = cophenet(Z, pdist(data_pca))                       # Finding cophenetic correlation for different linkages with city block distance\n",
    "    axs[i].annotate(\n",
    "        f\"Cophenetic\\nCorrelation\\n{coph_corr:0.2f}\",\n",
    "        (0.80, 0.80),\n",
    "        xycoords=\"axes fraction\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc8787a",
   "metadata": {},
   "source": [
    "**Observations and Insights:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d8fbb6",
   "metadata": {},
   "source": [
    "**Think about it:**\n",
    "\n",
    "- Can we clearly decide the number of clusters based on where to cut the dendrogram horizontally?\n",
    "- What is the next step in obtaining number of clusters based on the dendrogram?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d39f40",
   "metadata": {},
   "source": [
    "**Let's have a look at the dendrograms for different linkages with `Chebyshev distance`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26690933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the dendrogram for Chebyshev distance with linkages single, complete and average. \n",
    "# Hint: Use Chebyshev distance as the metric in the linkage() function \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dc3441",
   "metadata": {},
   "source": [
    "**Observations and Insights:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29addff5",
   "metadata": {},
   "source": [
    "**Let's have a look at the dendrograms for different linkages with Mahalanobis distance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ba170a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the dendrogram for Mahalanobis distance with linkages single, complete and average. \n",
    "# Hint: Use Mahalanobis distance as the metric in the linkage() function \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc24b3c",
   "metadata": {},
   "source": [
    "**Observations and Insights:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8d76b8",
   "metadata": {},
   "source": [
    "**Let's have a look at the dendrograms for different linkages with Euclidean distance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5453b59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the dendrogram for Euclidean distance with linkages single, complete, average and ward. \n",
    "# Hint: Use Euclidean distance as the metric in the linkage() function \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ac3177",
   "metadata": {},
   "source": [
    "**Think about it:**\n",
    "\n",
    "- Are there any distinct clusters in any of the dendrograms?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017f94b8",
   "metadata": {},
   "source": [
    "**Observations and Insights:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0caef1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Agglomerative Clustering with affinity (distance) as Euclidean, linkage as 'Ward' with clusters=3\n",
    "HCmodel = AgglomerativeClustering(n_clusters=______, affinity=______, linkage=______,) \n",
    "\n",
    "# Fit on data_pca\n",
    "HCmodel.__________                                                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "65e893ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Agglomerative Clustering cluster labels to data_pca\n",
    "\n",
    "# Add Agglomerative Clustering cluster labels to the whole data\n",
    "\n",
    "# Add Agglomerative Clustering cluster labels to data_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ec7d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the distribution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fab854",
   "metadata": {},
   "source": [
    "**Let's visualize the clusters using PCA.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d799565c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hint: Use PCA_PLOT function created above\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87baf95",
   "metadata": {},
   "source": [
    "### **Cluster Profiling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a329ff4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the cluster-wise mean of all the variables. Hint: First group 'data' by cluster labels column and then find mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f934b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Highlight the maximum average value among all the clusters for each of the variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52260d8a",
   "metadata": {},
   "source": [
    "**Let's plot the boxplot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a60a12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create boxplot for each of the variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237ce2e9",
   "metadata": {},
   "source": [
    "### **Characteristics of each cluster**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3534a662",
   "metadata": {},
   "source": [
    "**Cluster 0:__________**\n",
    "\n",
    "**Summary for cluster 0:_______________** \n",
    "\n",
    "**Cluster 1:_______________**\n",
    "\n",
    "**Summary for cluster 1:_______________**\n",
    "\n",
    "\n",
    "**Cluster 2:_______________** \n",
    "\n",
    "**Summary for cluster 2:_______________**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b8aa74",
   "metadata": {},
   "source": [
    "**Observations and Insights:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37179889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping labels we got from Agglomerative Clustering since we will be using PCA data for prediction\n",
    "# Hint: Use axis=1 and inplace=True\n",
    "data_pca._____________\n",
    "data.____________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e425520",
   "metadata": {},
   "source": [
    "## **DBSCAN**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c941735",
   "metadata": {},
   "source": [
    "DBSCAN is a very powerful algorithm for finding high-density clusters, but the problem is determining the best set of hyperparameters to use with it. It includes two hyperparameters, `eps`, and `min samples`.\n",
    "\n",
    "Since it is an unsupervised algorithm, you have no control over it, unlike a supervised learning algorithm, which allows you to test your algorithm on a validation set. The approach we can follow is basically trying out a bunch of different combinations of values and finding the silhouette score for each of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480b6c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing lists\n",
    "eps_value = [2,3]                       # Taking random eps value\n",
    "min_sample_values = [6,20]              # Taking random min_sample value\n",
    "\n",
    "# Creating a dictionary for each of the values in eps_value with min_sample_values\n",
    "res = {eps_value[i]: min_sample_values for i in range(len(eps_value))}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c5e7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the silhouette_score for each of the combinations\n",
    "high_silhouette_avg = 0                                               # Assigning 0 to the high_silhouette_avg variable\n",
    "high_i_j = [0, 0]                                                     # Assigning 0's to the high_i_j list\n",
    "key = res.keys()                                                      # Assigning dictionary keys to a variable called key\n",
    "for i in key:\n",
    "    z = res[i]                                                        # Assigning dictionary values of each i to z\n",
    "    for j in z:\n",
    "        db = DBSCAN(eps=i, min_samples=j).fit(data_pca)               # Applying DBSCAN to each of the combination in dictionary\n",
    "        core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "        core_samples_mask[db.core_sample_indices_] = True\n",
    "        labels = db.labels_\n",
    "        silhouette_avg = silhouette_score(data_pca, labels)           # Finding silhouette score \n",
    "        print( \n",
    "            \"For eps value =\" + str(i),\n",
    "            \"For min sample =\" + str(j),\n",
    "            \"The average silhoutte_score is :\",\n",
    "            silhouette_avg,                                          # Printing the silhouette score for each of the combinations\n",
    "        )\n",
    "        if high_silhouette_avg < silhouette_avg:                     # If the silhouette score is greater than 0 or the previous score, it will get appended to the high_silhouette_avg list with its combination of i and j              \n",
    "            high_i_j[0] = i\n",
    "            high_i_j[1] = j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ce94a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the highest silhouette score\n",
    "print(\"Highest_silhoutte_avg is {} for eps = {} and min sample = {}\".format(high_silhouette_avg, high_i_j[0], high_i_j[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80247dce",
   "metadata": {},
   "source": [
    "**Now, let's apply DBSCAN using the hyperparameter values we have received above.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d118ef9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply DBSCAN using the above hyperparameter values\n",
    "dbs = _____________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa911be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit_predict on data_pca and add DBSCAN cluster labels to the whole data\n",
    "\n",
    "# fit_predict on data_pca and add DBSCAN cluster labels to data_model\n",
    "\n",
    "# fit_predict on data_pca and add DBSCAN cluster labels to data_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47699c3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's check the distribution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a311c74",
   "metadata": {},
   "source": [
    "**Let's visualize the clusters using PCA.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426e7f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hint: Use PCA_PLOT function created above\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a80374c",
   "metadata": {},
   "source": [
    "**Observations and Insights:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de39ed10",
   "metadata": {},
   "source": [
    "**Think about it:**\n",
    "\n",
    "- Changing the eps and min sample values will result in different DBSCAN results? Can we try more value for eps and min_sample?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06334fb7",
   "metadata": {},
   "source": [
    "**Note:** You can experiment with different eps and min_sample values to see if DBSCAN produces good distribution and cluster profiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "1f0a7075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping labels we got from DBSCAN since we will be using PCA data for prediction\n",
    "# Hint: Use axis=1 and inplace=True\n",
    "data_pca._____________\n",
    "data.____________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30613efa",
   "metadata": {},
   "source": [
    "## **Gaussian Mixture Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fca82b0",
   "metadata": {},
   "source": [
    "**Let's find the silhouette score for K=5 in Gaussian Mixture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4ade2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm = GaussianMixture(_______) # Initialize Gaussian Mixture Model with number of clusters as 5 and random_state=1\n",
    "\n",
    "preds = ___________            # Fit and predict Gaussian Mixture Model using data_pca\n",
    "\n",
    "score = ____________           # Calculate the silhouette score\n",
    "\n",
    "print(score)                   # Print the score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0c8dc6",
   "metadata": {},
   "source": [
    "**Observations and Insights:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b4f14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting on data_pca and add Gaussian Mixture Model cluster labels to the whole data\n",
    "\n",
    "# Predicting on data_pca and add Gaussian Mixture Model cluster labels to data_model\n",
    "\n",
    "# Predicting on data_pca and add Gaussian Mixture Model cluster labels to data_pca\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1f8dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the distribution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642ebb6b",
   "metadata": {},
   "source": [
    "**Let's visualize the clusters using PCA.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52969ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hint: Use PCA_PLOT function created above\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e536e1",
   "metadata": {},
   "source": [
    "### **Cluster Profiling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2fb20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the cluster-wise mean of all the variables. Hint: First group 'data' by cluster labels column and then find mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280c66a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Highlight the maximum average value among all the clusters for each of the variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a2d324",
   "metadata": {},
   "source": [
    "**Let's plot the boxplot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695c58f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create boxplot for each of the variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10442989",
   "metadata": {},
   "source": [
    "### **Characteristics of each cluster**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f776b12",
   "metadata": {},
   "source": [
    "**Cluster 0:__________**\n",
    "\n",
    "**Summary for cluster 0:_______________** \n",
    "\n",
    "**Cluster 1:_______________**\n",
    "\n",
    "**Summary for cluster 1:_______________**\n",
    "\n",
    "\n",
    "**Cluster 2:_______________** \n",
    "\n",
    "**Summary for cluster 2:_______________**\n",
    "\n",
    "**Cluster 3:_______________** \n",
    "\n",
    "**Summary for cluster 3:_______________**\n",
    "\n",
    "**Cluster 4:_______________** \n",
    "\n",
    "**Summary for cluster 4:_______________**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73367782",
   "metadata": {},
   "source": [
    "## **Conclusion and Recommendations**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a079c575",
   "metadata": {},
   "source": [
    "- **Refined Insights:** What are the most meaningful insights from the data relevant to the problem?\n",
    "\n",
    "- **Comparison of various techniques and their relative performance:** How do different techniques perform? Which one is performing relatively better? Is there scope to improve the performance further?\n",
    "\n",
    "- **Proposal for the final solution design:** What model do you propose to be adopted? Why is this the best solution to adopt?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
